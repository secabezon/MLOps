# MLOps - Proyecto de Riesgo Crediticio

## ğŸ“‹ DescripciÃ³n del Proyecto

Proyecto MLOps del Tec de Monterrey 2025 que implementa un pipeline completo de Machine Learning para predecir riesgo crediticio utilizando el dataset German Credit.

### ProblemÃ¡tica
EvaluaciÃ³n automatizada de riesgo crediticio para mejorar la toma de decisiones en otorgamiento de crÃ©ditos, reduciendo el riesgo de impago y optimizando la aprobaciÃ³n de solicitantes.

### SoluciÃ³n MLOps
Sistema de Machine Learning end-to-end con:
- Pipeline automatizado de datos y entrenamiento
- Servicio de predicciones vÃ­a API REST
- Monitoreo de data drift y performance
- Reproducibilidad y versionamiento con DVC/MLflow
- Despliegue containerizado con Docker

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data      â”‚
â”‚   (DVC)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing   â”‚
â”‚  Pipeline       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Training  â”‚â”€â”€â”€â”€â”€â–¶â”‚   MLflow     â”‚
â”‚  (sklearn)      â”‚      â”‚  Tracking    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Artifact  â”‚â”€â”€â”€â”€â”€â–¶â”‚     DVC      â”‚
â”‚   (.joblib)     â”‚      â”‚   Storage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI        â”‚
â”‚  Service        â”‚
â”‚  (Docker)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Predictions    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Estructura del Proyecto

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/              # Scripts de procesamiento de datos
â”‚   â”œâ”€â”€ features/          # Feature engineering (Preprocessor)
â”‚   â”œâ”€â”€ models/            # Entrenamiento y predicciÃ³n
â”‚   â”‚   â””â”€â”€ artifacts/     # Modelos entrenados (.joblib)
â”‚   â”œâ”€â”€ monitoring/        # Data drift y performance
â”‚   â””â”€â”€ pipelines/         # sklearn Pipelines
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py            # CLI principal para entrenar/evaluar
â”‚   â”œâ”€â”€ dvc_*.py           # Wrappers para DVC pipeline
â”‚   â””â”€â”€ API/
â”‚       â”œâ”€â”€ main_fastapi.py  # Servidor FastAPI
â”‚       â”œâ”€â”€ schemas.py       # ValidaciÃ³n Pydantic
â”‚       â””â”€â”€ my_routes/       # Endpoints
â”œâ”€â”€ tests/                 # Pruebas unitarias e integraciÃ³n
â”œâ”€â”€ notebooks/             # AnÃ¡lisis exploratorio
â”œâ”€â”€ docs/                  # DocumentaciÃ³n adicional
â”œâ”€â”€ Dockerfile             # Imagen Docker optimizada
â”œâ”€â”€ dvc.yaml               # Pipeline DVC
â”œâ”€â”€ requirements.txt       # Dependencias Python
â””â”€â”€ README.md
```

---

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos
- Python 3.11+
- Docker (opcional, para containerizaciÃ³n)
- Git

### InstalaciÃ³n

```powershell
# Clonar repositorio
git clone https://dagshub.com/Pamela-ruiz9/MLOps.git
cd MLOps

# Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar DVC (opcional, para datos versionados)
dvc remote add -d dagshub https://dagshub.com/Pamela-ruiz9/MLOps.dvc
dvc pull
```

---

## ğŸ§ª Pruebas Automatizadas

### Ejecutar Todas las Pruebas

```powershell
# Activar entorno
.venv\Scripts\activate

# Ejecutar tests con pytest
pytest -v

# Con reporte de cobertura
pytest --cov=src --cov-report=html

# Solo tests rÃ¡pidos
pytest -q
```

### Tipos de Pruebas Implementadas

- **Unitarias** (`tests/test_preprocessing.py`, `test_model.py`)
  - Preprocessor: fit, transform, manejo de missing values
  - Modelos: carga, predicciones, probabilidades
  - MÃ©tricas: accuracy, F1, ROC-AUC

- **IntegraciÃ³n** (`tests/test_integration.py`)
  - Pipeline end-to-end: carga â†’ preprocesamiento â†’ predicciÃ³n â†’ evaluaciÃ³n
  - Reproducibilidad de resultados
  - GeneraciÃ³n y detecciÃ³n de data drift

- **API** (`tests/test_api.py`)
  - Endpoints `/predict` y `/predict-csv`
  - ValidaciÃ³n de entrada/salida
  - Manejo de errores

---

## ğŸ”§ Uso del Modelo

### Entrenamiento Local

```powershell
# Entrenar modelo con configuraciÃ³n por defecto
python scripts/main.py --train

# Entrenar Random Forest con hiperparÃ¡metros
python scripts/main.py --train --model rf --model-param n_estimators=200 --model-param max_depth=10

# Dry-run (sin guardar)
python scripts/main.py --dry-run --model logreg
```

### Pipeline DVC (Reproducible)

```powershell
# Reproducir pipeline completo
dvc repro

# Ver DAG del pipeline
dvc dag

# Sincronizar artefactos con remoto
dvc push
```

### Predicciones

```python
import joblib
import pandas as pd

# Cargar modelo
model = joblib.load('src/models/artifacts/model.joblib')

# Preparar datos
data = pd.DataFrame({...})

# Predecir
predictions = model.predict(data)
```

---

## ğŸŒ API REST (FastAPI)

### Iniciar Servidor Localmente

```powershell
# OpciÃ³n 1: uvicorn directo
uvicorn scripts.API.main_fastapi:app --host 0.0.0.0 --port 8001 --reload

# OpciÃ³n 2: Con dependencias de API
pip install -r requirements_api.txt
uvicorn scripts.API.main_fastapi:app --port 8001
```

### DocumentaciÃ³n Interactiva

Una vez iniciado el servidor, visita:
- **Swagger UI**: http://localhost:8001/docs
- **ReDoc**: http://localhost:8001/redoc

### Endpoints Disponibles

#### `GET /` - Health Check
```bash
curl http://localhost:8001/
```

Respuesta:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "model_loaded": true
}
```

#### `POST /app-credit/predict/` - PredicciÃ³n Individual

```bash
curl -X POST http://localhost:8001/app-credit/predict/ \
  -H "Content-Type: application/json" \
  -d '{
    "laufkont": "A11",
    "laufzeit": 24,
    "moral": "A30",
    "verw": "A40",
    "hoehe": 5000,
    "sparkont": "A61",
    "beszeit": "A71",
    "rate": 2,
    "famges": "A91",
    "buerge": "A101",
    "wohnzeit": 2,
    "verm": "A121",
    "alter": 35,
    "weitkred": "A141",
    "wohn": "A151",
    "bishkred": "2",
    "beruf": "A171",
    "pers": "1",
    "telef": "A191",
    "gastarb": "A201"
  }'
```

Respuesta:
```json
{
  "prediccion": 0
}
```

#### `POST /app-credit/predict-csv/` - PredicciÃ³n Batch

```bash
curl -X POST http://localhost:8001/app-credit/predict-csv/ \
  -F "file=@datos.csv"
```

Respuesta:
```json
{
  "predicciones": [0, 1, 0, 1],
  "total": 4
}
```

### Schemas (ValidaciÃ³n Pydantic)

La API valida automÃ¡ticamente:
- **Tipos de datos**: int, str segÃºn campo
- **Rangos**: edad (18-100), laufzeit (1-100), rate (1-4)
- **Campos requeridos**: todos los 20 features del modelo

Ejemplo de error de validaciÃ³n:
```json
{
  "detail": [
    {
      "loc": ["body", "alter"],
      "msg": "ensure this value is greater than or equal to 18",
      "type": "value_error"
    }
  ]
}
```

---

## ğŸ³ Docker

### ConstrucciÃ³n de Imagen

```powershell
# Build
docker build -t ml-service:latest .

# Build con tag versionado
docker build -t ml-service:v1.0.0 .
```

### EjecuciÃ³n del Contenedor

```powershell
# Ejecutar en puerto 8001
docker run -p 8001:8001 ml-service:latest

# Con variables de entorno
docker run -p 8001:8001 \
  -e MLFLOW_TRACKING_URI=https://dagshub.com/Pamela-ruiz9/MLOps.mlflow \
  ml-service:latest
```

### Publicar en DockerHub

```powershell
# Login
docker login

# Tag para DockerHub
docker tag ml-service:latest <usuario>/mlops-credit:v1.0.0

# Push
docker push <usuario>/mlops-credit:v1.0.0
```

### Optimizaciones del Dockerfile

- Base image: `python:3.11-slim` (tamaÃ±o reducido)
- Multi-layer caching: copia requirements primero
- `.dockerignore`: excluye venv, notebooks, tests
- Dependencias mÃ­nimas: solo `requirements_api.txt`

---

## ğŸ“Š Monitoreo y Data Drift

### Generar Datos con Drift

```powershell
python src/monitoring/make_drift.py
```

Esto crea `src/data/drift/german_credit_drift.csv` con drift sintÃ©tico (distribuciÃ³n numÃ©rica alterada ~5%).

### Detectar Drift y Alertas

```powershell
# AnÃ¡lisis estadÃ­stico (KS-test)
python src/monitoring/drfit_alerts.py
```

Salida ejemplo:
```
=== DATA DRIFT ALERTS ===

â¡ Dataset drift: True
â¡ Drift share: 0.45
â¡ Columns with drift (9):
laufzeit, hoehe, rate, wohnzeit, alter

=== RECOMMENDATIONS ===
âš ï¸ Drift severo â†’ retraining recomendado.
```

### EvaluaciÃ³n de Performance

```powershell
python src/monitoring/performance.py
```

Compara mÃ©tricas (accuracy, F1, ROC-AUC) entre:
- Dataset de validaciÃ³n (baseline)
- Dataset con drift

Genera: `reports/performance_comparison.csv`

### Dashboard con Evidently

```powershell
python src/monitoring/compute_drift_metrics.py
```

Genera dashboard HTML interactivo en `reports/` con visualizaciones de drift por feature.

---

## ğŸ”„ Reproducibilidad

### Semillas Aleatorias

Todas las operaciones con componentes aleatorios usan semillas fijas:

```python
# En scripts/main.py y entrenamiento
import numpy as np
import random

random.seed(42)
np.random.seed(42)
```

### Versionamiento de Artefactos

**Datos** (DVC):
```powershell
# Versionar dataset procesado
dvc add src/data/processed/german_credit_clean.csv
git add src/data/processed/german_credit_clean.csv.dvc
git commit -m "Version processed data"
dvc push
```

**Modelos** (MLflow + DVC):
- MLflow tracking: parÃ¡metros, mÃ©tricas, artifacts automÃ¡ticos
- DVC: modelo `.joblib` en `src/models/artifacts/`

Acceso a modelos versionados:
- **MLflow**: `https://dagshub.com/Pamela-ruiz9/MLOps.mlflow`
- **Modelo registrado**: `models:/credit-risk-model/Production` (MLflow Model Registry)

### VerificaciÃ³n en Entorno Limpio

```powershell
# En mÃ¡quina/VM/contenedor nuevo
git clone <repo>
cd MLOps

# Instalar dependencias fijadas
pip install -r requirements.txt

# Descargar datos y modelo
dvc pull

# Reproducir pipeline
dvc repro

# Comparar mÃ©tricas con referencia
python scripts/main.py --train
# Verificar que accuracy/F1/ROC-AUC coincidan Â±0.01
```

---

## ğŸ“ˆ Experimentos MLflow

### Tracking Local

```powershell
# Ver experimentos localmente
mlflow ui

# Abrir en navegador
# http://localhost:5000
```

### Sincronizar con DagsHub

```powershell
# Configurar remote
$env:MLFLOW_TRACKING_URI="https://dagshub.com/Pamela-ruiz9/MLOps.mlflow"
$env:MLFLOW_TRACKING_USERNAME="<usuario>"
$env:MLFLOW_TRACKING_PASSWORD="<token>"

# Importar experimentos locales a remoto
python scripts/import_mlflow_to_remote.py
```

Ver experimentos en: https://dagshub.com/Pamela-ruiz9/MLOps.mlflow

---

## ğŸ“š DocumentaciÃ³n Adicional

- [`docs/dvc_pipeline.md`](docs/dvc_pipeline.md) - GuÃ­a completa de DVC
- [`docs/dataset_modifications.md`](docs/dataset_modifications.md) - Transformaciones de datos
- [DagsHub Repo](https://dagshub.com/Pamela-ruiz9/MLOps) - CÃ³digo, datos, modelos

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| Componente | TecnologÃ­a |
|-----------|-----------|
| ML Framework | scikit-learn, XGBoost |
| Pipeline | sklearn Pipeline, ColumnTransformer |
| Tracking | MLflow |
| Versionamiento | DVC, Git |
| API | FastAPI, Pydantic |
| Testing | pytest, pytest-cov |
| ContainerizaciÃ³n | Docker |
| Drift Detection | Evidently, scipy (KS-test) |
| Remote Storage | DagsHub |

---

## ğŸ‘¥ Equipo

**Proyecto MLOps - Equipo 5**  
Tec de Monterrey 2025

---

## ğŸ“„ Licencia

Ver archivo `LICENSE` para detalles.

---

## ğŸ”— Enlaces Ãštiles

- **Repositorio Git**: https://github.com/secabezon/MLOps
- **DagsHub (DVC + MLflow)**: https://dagshub.com/Pamela-ruiz9/MLOps
- **MLflow UI**: https://dagshub.com/Pamela-ruiz9/MLOps.mlflow
- **DocumentaciÃ³n FastAPI**: https://fastapi.tiangolo.com/
- **DVC Docs**: https://dvc.org/doc
