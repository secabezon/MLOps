# MLOps - Proyecto de Riesgo Crediticio

## üìã Descripci√≥n del Proyecto

Proyecto MLOps del Tec de Monterrey 2025 que implementa un pipeline completo de Machine Learning para predecir riesgo crediticio utilizando el dataset German Credit.

### Problem√°tica
Evaluaci√≥n automatizada de riesgo crediticio para mejorar la toma de decisiones en otorgamiento de cr√©ditos, reduciendo el riesgo de impago y optimizando la aprobaci√≥n de solicitantes.

### Soluci√≥n MLOps
Sistema de Machine Learning end-to-end con:
- Pipeline automatizado de datos y entrenamiento
- Servicio de predicciones v√≠a API REST
- Monitoreo de data drift y performance
- Reproducibilidad y versionamiento con DVC/MLflow
- Despliegue containerizado con Docker

---

## üèóÔ∏è Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Raw Data      ‚îÇ
‚îÇ   (DVC)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Preprocessing   ‚îÇ
‚îÇ  Pipeline       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model Training  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   MLflow     ‚îÇ
‚îÇ  (sklearn)      ‚îÇ      ‚îÇ  Tracking    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Model Artifact  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ     DVC      ‚îÇ
‚îÇ   (.joblib)     ‚îÇ      ‚îÇ   Storage    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FastAPI        ‚îÇ
‚îÇ  Service        ‚îÇ
‚îÇ  (Docker)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Predictions    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Estructura del Proyecto

```
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Scripts de procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ features/          # Feature engineering (Preprocessor)
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Entrenamiento y predicci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ artifacts/     # Modelos entrenados (.joblib)
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/        # Data drift y performance
‚îÇ   ‚îî‚îÄ‚îÄ pipelines/         # sklearn Pipelines
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # CLI principal para entrenar/evaluar
‚îÇ   ‚îú‚îÄ‚îÄ dvc_*.py           # Wrappers para DVC pipeline
‚îÇ   ‚îî‚îÄ‚îÄ API/
‚îÇ       ‚îú‚îÄ‚îÄ main_fastapi.py  # Servidor FastAPI
‚îÇ       ‚îú‚îÄ‚îÄ schemas.py       # Validaci√≥n Pydantic
‚îÇ       ‚îî‚îÄ‚îÄ my_routes/       # Endpoints
‚îú‚îÄ‚îÄ tests/                 # Pruebas unitarias e integraci√≥n
‚îú‚îÄ‚îÄ notebooks/             # An√°lisis exploratorio
‚îú‚îÄ‚îÄ docs/                  # Documentaci√≥n adicional
‚îú‚îÄ‚îÄ Dockerfile             # Imagen Docker optimizada
‚îú‚îÄ‚îÄ dvc.yaml               # Pipeline DVC
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Inicio R√°pido

### Prerrequisitos
- Python 3.11+
- Docker (opcional, para containerizaci√≥n)
- Git

### Instalaci√≥n

```powershell
# Clonar repositorio
git clone https://dagshub.com/Pamela-ruiz9/MLOps.git
cd MLOps

# Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar DVC (opcional, para datos versionados)
dvc remote add -d dagshub https://dagshub.com/Pamela-ruiz9/MLOps.dvc
dvc pull
```

---

## üß™ Pruebas Automatizadas

### Ejecutar Todas las Pruebas

```powershell
# Activar entorno
.venv\Scripts\activate

# Ejecutar tests con pytest
pytest -v

# Con reporte de cobertura
pytest --cov=src --cov-report=html

# Solo tests r√°pidos
pytest -q
```

### Tipos de Pruebas Implementadas

- **Unitarias** (`tests/test_preprocessing.py`, `test_model.py`)
  - Preprocessor: fit, transform, manejo de missing values
  - Modelos: carga, predicciones, probabilidades
  - M√©tricas: accuracy, F1, ROC-AUC

- **Integraci√≥n** (`tests/test_integration.py`)
  - Pipeline end-to-end: carga ‚Üí preprocesamiento ‚Üí predicci√≥n ‚Üí evaluaci√≥n
  - Reproducibilidad de resultados
  - Generaci√≥n y detecci√≥n de data drift

- **API** (`tests/test_api.py`)
  - Endpoints `/predict` y `/predict-csv`
  - Validaci√≥n de entrada/salida
  - Manejo de errores

---

## üîß Uso del Modelo

### Entrenamiento Local

```powershell
# Entrenar modelo con configuraci√≥n por defecto
python scripts/main.py --train

# Entrenar Random Forest con hiperpar√°metros
python scripts/main.py --train --model rf --model-param n_estimators=200 --model-param max_depth=10

# Dry-run (sin guardar)
python scripts/main.py --dry-run --model logreg
```

### Pipeline DVC (Reproducible)

```powershell
# Reproducir pipeline completo
dvc repro

# Ver DAG del pipeline
dvc dag

# Sincronizar artefactos con remoto
dvc push
```

### Predicciones

```python
import joblib
import pandas as pd

# Cargar modelo
model = joblib.load('src/models/artifacts/model.joblib')

# Preparar datos
data = pd.DataFrame({...})

# Predecir
predictions = model.predict(data)
```

---

## üåê API REST (FastAPI)

### Iniciar Servidor Localmente

```powershell
# Opci√≥n 1: uvicorn directo
uvicorn scripts.API.main_fastapi:app --host 0.0.0.0 --port 8001 --reload

# Opci√≥n 2: Con dependencias de API
pip install -r requirements_api.txt
uvicorn scripts.API.main_fastapi:app --port 8001
```

### Documentaci√≥n Interactiva

Una vez iniciado el servidor, visita:
- **Swagger UI**: http://localhost:8001/docs
- **ReDoc**: http://localhost:8001/redoc

### Endpoints Disponibles

#### `GET /` - Health Check
```bash
curl http://localhost:8001/
```

Respuesta:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "model_loaded": true
}
```

#### `POST /app-credit/predict/` - Predicci√≥n Individual

```bash
curl -X POST http://localhost:8001/app-credit/predict/ \
  -H "Content-Type: application/json" \
  -d '{
    "laufkont": "A11",
    "laufzeit": 24,
    "moral": "A30",
    "verw": "A40",
    "hoehe": 5000,
    "sparkont": "A61",
    "beszeit": "A71",
    "rate": 2,
    "famges": "A91",
    "buerge": "A101",
    "wohnzeit": 2,
    "verm": "A121",
    "alter": 35,
    "weitkred": "A141",
    "wohn": "A151",
    "bishkred": "2",
    "beruf": "A171",
    "pers": "1",
    "telef": "A191",
    "gastarb": "A201"
  }'
```

Respuesta:
```json
{
  "prediccion": 0
}
```

#### `POST /app-credit/predict-csv/` - Predicci√≥n Batch

```bash
curl -X POST http://localhost:8001/app-credit/predict-csv/ \
  -F "file=@datos.csv"
```

Respuesta:
```json
{
  "predicciones": [0, 1, 0, 1],
  "total": 4
}
```

### Schemas (Validaci√≥n Pydantic)

La API valida autom√°ticamente:
- **Tipos de datos**: int, str seg√∫n campo
- **Rangos**: edad (18-100), laufzeit (1-100), rate (1-4)
- **Campos requeridos**: todos los 20 features del modelo

Ejemplo de error de validaci√≥n:
```json
{
  "detail": [
    {
      "loc": ["body", "alter"],
      "msg": "ensure this value is greater than or equal to 18",
      "type": "value_error"
    }
  ]
}
```

---

## üê≥ Docker

### Construcci√≥n de Imagen

```powershell
# Build
docker build -t ml-service:latest .

# Build con tag versionado
docker build -t ml-service:v1.0.0 .
```

### Ejecuci√≥n del Contenedor

```powershell
# Ejecutar en puerto 8001
docker run -p 8001:8001 ml-service:latest

# Con variables de entorno
docker run -p 8001:8001 \
  -e MLFLOW_TRACKING_URI=https://dagshub.com/Pamela-ruiz9/MLOps.mlflow \
  ml-service:latest
```

### Publicar en DockerHub

```powershell
# Login con usuario ingridpamer
docker login -u ingridpamer

# Tag para DockerHub
docker tag ml-service:latest ingridpamer/mlops-credit-api:v1.0.0

# Push
docker push ingridpamer/mlops-credit-api:v1.0.0
```

### Usar Imagen desde DockerHub

La imagen Docker est√° publicada y disponible para usar directamente:

**Docker Hub Repository**: [ingridpamer/mlops-credit-api](https://hub.docker.com/r/ingridpamer/mlops-credit-api)

```powershell
# Pull de la imagen
docker pull ingridpamer/mlops-credit-api:latest

# Ejecutar contenedor
docker run -p 8001:8001 ingridpamer/mlops-credit-api:latest

# Verificar que funciona
curl http://localhost:8001/docs
```

> **Nota**: Para publicar sin instalar Docker localmente, consulta la gu√≠a en `DOCKER_HUB_SIN_INSTALACION.md` que incluye m√©todos alternativos como GitHub Actions y Play with Docker.

### Optimizaciones del Dockerfile

- Base image: `python:3.11-slim` (tama√±o reducido)
- Multi-layer caching: copia requirements primero
- `.dockerignore`: excluye venv, notebooks, tests
- Dependencias m√≠nimas: solo `requirements_api.txt`

---

## üìä Monitoreo y Data Drift

### Generar Datos con Drift

```powershell
python src/monitoring/make_drift.py
```

Esto crea `src/data/drift/german_credit_drift.csv` con drift sint√©tico (distribuci√≥n num√©rica alterada ~5%).

### Detectar Drift y Alertas

```powershell
# An√°lisis estad√≠stico (KS-test)
python src/monitoring/drfit_alerts.py
```

Salida ejemplo:
```
=== DATA DRIFT ALERTS ===

‚û° Dataset drift: True
‚û° Drift share: 0.45
‚û° Columns with drift (9):
laufzeit, hoehe, rate, wohnzeit, alter

=== RECOMMENDATIONS ===
‚ö†Ô∏è Drift severo ‚Üí retraining recomendado.
```

### Evaluaci√≥n de Performance

```powershell
python src/monitoring/performance.py
```

Compara m√©tricas (accuracy, F1, ROC-AUC) entre:
- Dataset de validaci√≥n (baseline)
- Dataset con drift

Genera: `reports/performance_comparison.csv`

### Dashboard con Evidently

```powershell
python src/monitoring/compute_drift_metrics.py
```

Genera dashboard HTML interactivo en `reports/` con visualizaciones de drift por feature.

---

## üîÑ Reproducibilidad

### Semillas Aleatorias

Todas las operaciones con componentes aleatorios usan semillas fijas:

```python
# En scripts/main.py y entrenamiento
import numpy as np
import random

random.seed(42)
np.random.seed(42)
```

### Versionamiento de Artefactos

**Datos** (DVC):
```powershell
# Versionar dataset procesado
dvc add src/data/processed/german_credit_clean.csv
git add src/data/processed/german_credit_clean.csv.dvc
git commit -m "Version processed data"
dvc push
```

**Modelos** (MLflow + DVC):
- MLflow tracking: par√°metros, m√©tricas, artifacts autom√°ticos
- DVC: modelo `.joblib` en `src/models/artifacts/`

Acceso a modelos versionados:
- **MLflow**: `https://dagshub.com/Pamela-ruiz9/MLOps.mlflow`
- **Modelo registrado**: `models:/credit-risk-model/Production` (MLflow Model Registry)

### Verificaci√≥n en Entorno Limpio

```powershell
# En m√°quina/VM/contenedor nuevo
git clone <repo>
cd MLOps

# Instalar dependencias fijadas
pip install -r requirements.txt

# Descargar datos y modelo
dvc pull

# Reproducir pipeline
dvc repro

# Comparar m√©tricas con referencia
python scripts/main.py --train
# Verificar que accuracy/F1/ROC-AUC coincidan ¬±0.01
```

---

## üìà Experimentos MLflow

### Tracking Local

```powershell
# Ver experimentos localmente
mlflow ui

# Abrir en navegador
# http://localhost:5000
```

### Sincronizar con DagsHub

```powershell
# Configurar remote
$env:MLFLOW_TRACKING_URI="https://dagshub.com/Pamela-ruiz9/MLOps.mlflow"
$env:MLFLOW_TRACKING_USERNAME="<usuario>"
$env:MLFLOW_TRACKING_PASSWORD="<token>"

# Importar experimentos locales a remoto
python scripts/import_mlflow_to_remote.py
```

Ver experimentos en: https://dagshub.com/Pamela-ruiz9/MLOps.mlflow

---

## üìö Documentaci√≥n Adicional

- [`docs/dvc_pipeline.md`](docs/dvc_pipeline.md) - Gu√≠a completa de DVC
- [`docs/dataset_modifications.md`](docs/dataset_modifications.md) - Transformaciones de datos
- [DagsHub Repo](https://dagshub.com/Pamela-ruiz9/MLOps) - C√≥digo, datos, modelos

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

| Componente | Tecnolog√≠a |
|-----------|-----------|
| ML Framework | scikit-learn, XGBoost |
| Pipeline | sklearn Pipeline, ColumnTransformer |
| Tracking | MLflow |
| Versionamiento | DVC, Git |
| API | FastAPI, Pydantic |
| Testing | pytest, pytest-cov |
| Containerizaci√≥n | Docker |
| Drift Detection | Evidently, scipy (KS-test) |
| Remote Storage | DagsHub |

---

## üë• Equipo

**Proyecto MLOps - Equipo 5**  
Tec de Monterrey 2025

---

## üìÑ Licencia

Ver archivo `LICENSE` para detalles.

---

## üîó Enlaces √ötiles

- **Repositorio Git**: https://github.com/secabezon/MLOps
- **DagsHub (DVC + MLflow)**: https://dagshub.com/Pamela-ruiz9/MLOps
- **MLflow UI**: https://dagshub.com/Pamela-ruiz9/MLOps.mlflow
- **Documentaci√≥n FastAPI**: https://fastapi.tiangolo.com/
- **DVC Docs**: https://dvc.org/doc
